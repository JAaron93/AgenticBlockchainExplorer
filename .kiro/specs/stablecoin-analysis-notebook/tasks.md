# Implementation Plan

- [x] 1. Set up marimo notebook structure and dependencies
  - [x] 1.1 Create the marimo notebook file with initial imports and configuration
    - Create `notebooks/stablecoin_analysis.py` as a marimo notebook
    - Add imports for marimo, pandas, altair, decimal, dataclasses, pathlib
    - Configure marimo app with title and description
    - _Requirements: 1.1_
  - [x] 1.2 Update project dependencies
    - Add marimo, altair, hypothesis to requirements.txt
    - Verify compatibility with existing dependencies
    - _Requirements: 1.1_

- [x] 2. Implement data loading and validation
  - [x] 2.1 Create schema validation functions
    - Implement `validate_schema(data: dict) -> tuple[bool, list[str]]`
    - Validate metadata, summary, transactions, and holders sections
    - Return list of validation errors for invalid data
    - _Requirements: 1.2, 1.4_
  - [x] 2.2 Write property test for schema validation round-trip
    - **Property 1: Schema validation round-trip**
    - **Validates: Requirements 1.2, 8.2**
  - [x] 2.3 Create JSON file loader and DataFrame converter
    - Implement `load_json_file(file_path: str) -> LoadedData`
    - Parse JSON and convert transactions/holders to DataFrames
    - Handle decimal conversion for amount fields
    - Parse ISO8601 timestamps to datetime objects
    - _Requirements: 1.2, 1.3_
  - [x] 2.4 Create file selector UI cell
    - Add marimo file browser for output directory
    - Display metadata after file selection
    - Show error messages for invalid files
    - _Requirements: 1.1, 1.5_

- [x] 3. Implement activity type analysis
  - [x] 3.1 Create activity breakdown calculation functions
    - Implement `analyze_activity_types(df: pd.DataFrame) -> ActivityBreakdown`
    - Calculate counts, percentages, volumes by activity type
    - _Requirements: 2.1, 2.3_
  - [x] 3.2 Write property test for grouping preserves totals
    - **Property 2: Grouping preserves totals**
    - **Validates: Requirements 2.1, 3.1, 6.1**
  - [x] 3.3 Write property test for percentages sum to 100
    - **Property 3: Percentages sum to 100**
    - **Validates: Requirements 2.1, 4.1**
  - [x] 3.4 Create activity breakdown visualization cell
    - Implement pie chart for activity type distribution
    - Implement bar chart for volume by activity type
    - Format amounts with currency notation
    - _Requirements: 2.2, 2.4_

- [x] 4. Implement stablecoin comparison analysis
  - [x] 4.1 Create stablecoin grouping and metrics functions
    - Implement grouping by stablecoin with activity distribution
    - Calculate average transaction size per stablecoin
    - Calculate store-of-value ratio per stablecoin
    - _Requirements: 3.1, 3.3, 3.4_
  - [x] 4.2 Write property test for volume calculation consistency
    - **Property 4: Volume calculation consistency**
    - **Validates: Requirements 2.3, 3.1, 6.1**
  - [x] 4.3 Write property test for average calculation correctness
    - **Property 5: Average calculation correctness**
    - **Validates: Requirements 3.3, 6.3**
  - [x] 4.4 Create stablecoin comparison visualization cell
    - Implement grouped bar chart comparing USDC vs USDT
    - Display average transaction size comparison
    - _Requirements: 3.2_

- [x] 5. Implement holder behavior analysis
  - [x] 5.1 Create holder metrics calculation functions
    - Implement `analyze_holders(holders_df, transactions_df) -> HolderMetrics`
    - Calculate SoV percentage, average balances, holding periods
    - Identify top 10 holders by balance
    - _Requirements: 4.1, 4.3, 4.4_
  - [x] 5.2 Write property test for holder classification consistency
    - **Property 6: Holder classification consistency**
    - **Validates: Requirements 4.1**
  - [x] 5.3 Write property test for top-N ordering correctness
    - **Property 7: Top-N ordering correctness**
    - **Validates: Requirements 4.4**
  - [x] 5.4 Create holder analysis visualization cell
    - Implement histogram of balances by SoV status
    - Display top holders table with classifications
    - _Requirements: 4.2, 4.4_

- [x] 6. Implement time series analysis
  - [x] 6.1 Create time series aggregation functions
    - Implement `analyze_time_series(df, aggregation) -> pd.DataFrame`
    - Support daily, weekly, monthly aggregations
    - Group by activity type and stablecoin
    - _Requirements: 5.1, 5.4_
  - [x] 6.2 Write property test for time aggregation preserves totals
    - **Property 8: Time aggregation preserves totals**
    - **Validates: Requirements 5.1, 5.4**
  - [x] 6.3 Create time series visualization cell
    - Implement line chart for transaction count over time
    - Implement line chart for volume over time
    - Add aggregation period selector UI
    - _Requirements: 5.2, 5.3, 5.4_

- [ ] 7. Implement chain comparison analysis
  - [ ] 7.1 Create chain metrics calculation functions
    - Implement `analyze_by_chain(df) -> list[ChainMetrics]`
    - Calculate transaction count, volume, avg size per chain
    - Calculate gas costs and SoV ratio per chain
    - _Requirements: 6.1, 6.3, 6.4_
  - [ ] 7.2 Create chain comparison visualization cell
    - Implement stacked bar chart for activity distribution per chain
    - Display chain metrics comparison table
    - _Requirements: 6.2_

- [ ] 8. Implement sample data generator and conclusions
  - [ ] 8.1 Create sample data generation functions
    - Implement `generate_sample_data(config) -> LoadedData`
    - Generate realistic transactions with proper distributions
    - Generate holders with SoV classifications
    - _Requirements: 8.1, 8.2_
  - [ ] 8.2 Write property test for sample data schema compliance
    - **Property 9: Sample data schema compliance**
    - **Validates: Requirements 8.2**
  - [ ] 8.3 Write property test for sample data respects configuration
    - **Property 10: Sample data respects configuration**
    - **Validates: Requirements 8.4**
  - [ ] 8.4 Create sample data UI controls and conclusion generation
    - Add configuration inputs for sample size, SoV ratio
    - Implement `generate_conclusions(results, data) -> list[Conclusion]`
    - Calculate overall transaction vs SoV ratio
    - _Implements Requirements: 7.1, 7.2 (conclusions), 8.3 (sample indicator), 8.4 (config UI)_
  - [ ] 8.5 Write property test for confidence calculation bounds
    - **Property 11: Confidence calculation bounds**
    - **Validates: Requirements 7.3**
  - [ ] 8.6 Write property test for error detection completeness
    - **Property 12: Error detection completeness**
    - **Validates: Requirements 7.4**
  - [ ] 8.7 Create summary panel visualization cell
    - Display key findings with confidence indicators
    - Show data quality warnings if errors present
    - _Requirements: 7.2, 7.3, 7.4_

- [ ] 9. Checkpoint - Ensure all analysis tests pass
  - Ensure all tests pass, ask the user if questions arise.

- [ ] 10. Set up ZenML infrastructure and collector steps
  - [ ] 10.1 Add ZenML dependencies and initialize project
    - Add zenml, scikit-learn, xgboost to requirements.txt
    - Run `zenml init` to initialize ZenML in the project
    - Configure ZenML stack (local orchestrator, artifact store)
    - _Requirements: 9.1, 10.1_
  - [ ] 10.2 Wrap Etherscan collector as ZenML step
    - Create `pipelines/steps/collectors.py`
    - Implement `etherscan_collector_step` with typed outputs
    - Handle API errors and return partial results
    - _Requirements: 9.1, 9.2, 9.4_
  - [ ] 10.3 Wrap BscScan and Polygonscan collectors as ZenML steps
    - Implement `bscscan_collector_step`
    - Implement `polygonscan_collector_step`
    - _Requirements: 9.1, 9.2_
  - [ ] 10.4 Create aggregation step
    - Implement `aggregate_data_step` to merge and deduplicate
    - Output versioned artifact with transactions and holders
    - _Requirements: 9.3, 9.5_
  - [ ] 10.5 Write property test for ZenML step output typing
    - **Property 13: ZenML step output typing**
    - **Validates: Requirements 9.1, 9.2**
  - [ ] 10.6 Write property test for aggregation preserves records
    - **Property 14: Aggregation preserves records**
    - **Validates: Requirements 9.3**

- [ ] 11. Create ZenML analysis pipeline
  - [ ] 11.1 Convert analysis functions to ZenML steps
    - Create `pipelines/steps/analysis.py`
    - Wrap `analyze_activity_types` as `activity_analysis_step`
    - Wrap `analyze_holders` as `holder_analysis_step`
    - Wrap `analyze_time_series` as `time_series_step`
    - Wrap `analyze_by_chain` as `chain_analysis_step`
    - _Requirements: 10.1, 10.2_
  - [ ] 11.2 Create data collection pipeline
    - Create `pipelines/collection_pipeline.py`
    - Chain collector steps with aggregation step
    - Support parameterization for stablecoins and date range
    - _Requirements: 10.3_
  - [ ] 11.3 Create analysis pipeline
    - Create `pipelines/analysis_pipeline.py`
    - Chain all analysis steps
    - Output analysis results as versioned artifacts
    - _Requirements: 10.2, 10.4_
  - [ ] 11.4 Write property test for pipeline artifact versioning
    - **Property 15: Pipeline artifact versioning**
    - **Validates: Requirements 10.2**

- [ ] 12. Implement ML feature engineering and SoV prediction
  - [ ] 12.1 Create feature engineering step
    - Create `pipelines/steps/ml.py`
    - Implement `feature_engineering_step`
    - Extract features: transaction_count, avg_transaction_size, balance_percentile, holding_period_days, activity_recency_days, transaction_frequency, balance_volatility, cross_chain_flag
    - _Requirements: 11.1, 12.2_
  - [ ] 12.2 Write property test for feature engineering completeness
    - **Property 16: Feature engineering completeness**
    - **Validates: Requirements 11.1, 12.2**
  - [ ] 12.3 Implement SoV prediction training step
    - Implement `train_sov_predictor_step`
    - Use RandomForest or XGBoost binary classifier
    - Calculate and log precision, recall, F1, AUC-ROC
    - Register model in ZenML model registry
    - _Requirements: 11.2, 11.3, 11.4_
  - [ ] 12.4 Implement SoV prediction inference step
    - Implement `predict_sov_step`
    - Load production model from registry
    - Output predictions with probabilities
    - _Requirements: 11.5_
  - [ ] 12.5 Write property test for SoV prediction probability bounds
    - **Property 17: SoV prediction probability bounds**
    - **Validates: Requirements 11.5**

- [ ] 13. Implement wallet behavior classifier
  - [ ] 13.1 Define wallet behavior classes and labeling logic
    - Create `pipelines/steps/wallet_classifier.py`
    - Define classes: trader, holder, whale, retail
    - Implement labeling function based on thresholds
    - _Requirements: 12.1_
  - [ ] 13.2 Implement wallet classifier training step
    - Implement `train_wallet_classifier_step`
    - Use multi-class RandomForest or XGBoost
    - Log metrics and register model
    - _Requirements: 12.3_
  - [ ] 13.3 Implement wallet classification inference step
    - Implement `classify_wallets_step`
    - Assign exactly one class per wallet with confidence
    - _Requirements: 12.4_
  - [ ] 13.4 Write property test for wallet classification exclusivity
    - **Property 18: Wallet classification exclusivity**
    - **Validates: Requirements 12.4**
  - [ ] 13.5 Write property test for model metrics validity
    - **Property 19: Model metrics validity**
    - **Validates: Requirements 11.3, 15.2**

- [ ] 14. Create master pipeline and Marimo-ZenML integration
  - [ ] 14.1 Create master pipeline
    - Create `pipelines/master_pipeline.py`
    - Chain collection, analysis, and ML inference
    - Support weekly cron scheduling configuration
    - _Requirements: 10.1, 10.5_
  - [ ] 14.2 Create ZenML-Marimo bridge
    - Create `notebooks/zenml_bridge.py`
    - Implement `ZenMLNotebookBridge` class
    - Methods: list_pipelines, trigger_pipeline, get_run_status, load_latest_artifacts
    - _Requirements: 13.1, 13.2, 13.3, 13.4_
  - [ ] 14.3 Write property test for pipeline trigger returns run_id
    - **Property 20: Pipeline trigger returns run_id**
    - **Validates: Requirements 13.2**
  - [ ] 14.4 Create pipeline control UI cells in marimo
    - Display available pipelines and status
    - Add "Run Pipeline" button with parameter inputs
    - Show progress indicators during execution
    - _Requirements: 13.1, 13.2, 13.3_

- [ ] 15. Implement visualization layer for pipeline outputs
  - [ ] 15.1 Create artifact loading cells
    - Load latest pipeline artifacts via ZenML bridge
    - Display run metadata (run_id, timestamp)
    - Add refresh mechanism for new results
    - _Requirements: 14.1, 14.4_
  - [ ] 15.2 Create ML prediction visualization cells
    - Display SoV prediction distribution chart
    - Display wallet behavior classification breakdown
    - Allow filtering analysis by behavior class
    - _Requirements: 12.5, 14.3_
  - [ ] 15.3 Create model comparison UI
    - Display table of model versions with metrics
    - Show production model indicator
    - Add model promotion controls
    - _Requirements: 15.1, 15.2, 15.3_

- [ ] 16. Implement web export and scheduling
  - [ ] 16.1 Create static export functionality
    - Generate static HTML/JSON outputs from notebook
    - Export visualizations as embeddable components
    - _Requirements: 14.5_
  - [ ] 16.2 Configure weekly scheduling
    - Document cron job setup for master pipeline
    - Create scheduling configuration file
    - _Requirements: 10.5_
  - [ ] 16.3 Add model performance monitoring
    - Implement metric threshold checking
    - Flag runs with degraded performance
    - _Requirements: 15.4, 15.5_

- [ ] 17. Checkpoint - Ensure all tests pass
  - Ensure all tests pass, ask the user if questions arise.

- [ ] 18. Integration and documentation
  - [ ] 18.1 Wire all cells together with reactive dependencies
    - Ensure proper cell ordering and dependencies
    - Add loading states for long computations
    - Test end-to-end flow from pipeline trigger to visualization
    - _Requirements: 1.1, 10.1, 13.3, 13.4, 14.1, 14.4_
  - [ ] 18.2 Add documentation and usage instructions
    - Add markdown cells explaining each analysis section
    - Document ZenML pipeline usage
    - Document ML model interpretation
    - Create deployment guide for live website
    - _Requirements: 8.3, 14.5_

- [ ] 19. Final Checkpoint - Ensure all tests pass
  - Ensure all tests pass, ask the user if questions arise.
